{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52bfeec0-bb6c-42d3-a4c9-1a8b7cfae22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the neural network with a kernel layer:\n",
      "tensor([[-0.0554],\n",
      "        [-0.0419],\n",
      "        [-0.0419]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom Kernel Layer using RBF Kernel\n",
    "class RBFLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, gamma=1.0):\n",
    "        super(RBFLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.gamma = gamma  # Parameter for the RBF kernel\n",
    "        self.centers = nn.Parameter(torch.randn(out_features, in_features))  # Learnable centers\n",
    "\n",
    "    def rbf_kernel(self, x, centers):\n",
    "        # Compute the RBF kernel: exp(-gamma * ||x - centers||^2)\n",
    "        distances = torch.cdist(x, centers, p=2)  # Euclidean distance\n",
    "        return torch.exp(-self.gamma * distances**2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the RBF kernel to the input\n",
    "        return self.rbf_kernel(x, self.centers)\n",
    "\n",
    "# Neural Network with a Kernel Layer\n",
    "class KernelNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, kernel_dim, gamma=1.0):\n",
    "        super(KernelNN, self).__init__()\n",
    "        self.kernel_layer = RBFLayer(input_dim, kernel_dim, gamma)\n",
    "        self.fc1 = nn.Linear(kernel_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.kernel_layer(x)  # Apply the kernel layer\n",
    "        x = self.relu(self.fc1(x))  # Fully connected layer with ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_dim = 2\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "kernel_dim = 20  # Number of RBF centers\n",
    "gamma = 1.0  # RBF kernel parameter\n",
    "\n",
    "# Create the model\n",
    "model = KernelNN(input_dim, hidden_dim, output_dim, kernel_dim, gamma)\n",
    "\n",
    "# Example input\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "print(\"Output of the neural network with a kernel layer:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7cde8-db45-46a0-a821-c8c6b48c6d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5043bee-9a54-4d7e-9eaa-e737bffef5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e93c188-2024-4a0a-a7cf-036c67a52c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the neural network with a custom kernel layer:\n",
      "tensor([[0.0078],\n",
      "        [0.0009],\n",
      "        [0.0009]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom Kernel Layer\n",
    "class KernelLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_fn):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features (int): Number of input features.\n",
    "            out_features (int): Number of output features (number of kernel centers).\n",
    "            kernel_fn (callable): A function that computes the kernel between two tensors.\n",
    "        \"\"\"\n",
    "        super(KernelLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.kernel_fn = kernel_fn\n",
    "        self.centers = nn.Parameter(torch.randn(out_features, in_features))  # Learnable centers\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "        Returns:\n",
    "            torch.Tensor: Transformed tensor of shape (batch_size, out_features).\n",
    "        \"\"\"\n",
    "        # Compute the kernel between input x and the learnable centers\n",
    "        return self.kernel_fn(x, self.centers)\n",
    "\n",
    "# Example Kernel Functions\n",
    "def rbf_kernel(x, centers, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Radial Basis Function (RBF) kernel.\n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "        centers (torch.Tensor): Centers tensor of shape (out_features, in_features).\n",
    "        gamma (float): Kernel parameter.\n",
    "    Returns:\n",
    "        torch.Tensor: Kernel output of shape (batch_size, out_features).\n",
    "    \"\"\"\n",
    "    distances = torch.cdist(x, centers, p=2)  # Euclidean distance\n",
    "    return torch.exp(-gamma * distances**2)\n",
    "\n",
    "def polynomial_kernel(x, centers, degree=2, c=1.0):\n",
    "    \"\"\"\n",
    "    Polynomial kernel.\n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "        centers (torch.Tensor): Centers tensor of shape (out_features, in_features).\n",
    "        degree (int): Degree of the polynomial.\n",
    "        c (float): Constant term.\n",
    "    Returns:\n",
    "        torch.Tensor: Kernel output of shape (batch_size, out_features).\n",
    "    \"\"\"\n",
    "    return (torch.matmul(x, centers.T) + c) ** degree\n",
    "\n",
    "# Neural Network with Custom Kernel Layer\n",
    "class KernelNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, kernel_dim, kernel_fn):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Number of input features.\n",
    "            hidden_dim (int): Number of hidden units in the fully connected layer.\n",
    "            output_dim (int): Number of output features.\n",
    "            kernel_dim (int): Number of kernel centers.\n",
    "            kernel_fn (callable): Kernel function to use in the kernel layer.\n",
    "        \"\"\"\n",
    "        super(KernelNN, self).__init__()\n",
    "        self.kernel_layer = KernelLayer(input_dim, kernel_dim, kernel_fn)\n",
    "        self.fc1 = nn.Linear(kernel_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.kernel_layer(x)  # Apply the kernel layer\n",
    "        x = self.relu(self.fc1(x))  # Fully connected layer with ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_dim = 2\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "kernel_dim = 20  # Number of kernel centers\n",
    "\n",
    "# Define the kernel function (e.g., RBF or polynomial)\n",
    "kernel_fn = lambda x, centers: rbf_kernel(x, centers, gamma=1.0)  # RBF kernel\n",
    "# kernel_fn = lambda x, centers: polynomial_kernel(x, centers, degree=2, c=1.0)  # Polynomial kernel\n",
    "\n",
    "# Create the model\n",
    "model = KernelNN(input_dim, hidden_dim, output_dim, kernel_dim, kernel_fn)\n",
    "\n",
    "# Example input\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "print(\"Output of the neural network with a custom kernel layer:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd941046-6962-4d4f-9e3d-9f4c501de6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.660855233669281\n",
      "Epoch 2, Loss: 0.6326214671134949\n",
      "Epoch 3, Loss: 0.6048409938812256\n",
      "Epoch 4, Loss: 0.5775526165962219\n",
      "Epoch 5, Loss: 0.5508005619049072\n",
      "Epoch 6, Loss: 0.5246261954307556\n",
      "Epoch 7, Loss: 0.4990682601928711\n",
      "Epoch 8, Loss: 0.4743987023830414\n",
      "Epoch 9, Loss: 0.45087575912475586\n",
      "Epoch 10, Loss: 0.42792555689811707\n",
      "Epoch 11, Loss: 0.4056072235107422\n",
      "Epoch 12, Loss: 0.38398146629333496\n",
      "Epoch 13, Loss: 0.363110214471817\n",
      "Epoch 14, Loss: 0.34305694699287415\n",
      "Epoch 15, Loss: 0.3238866627216339\n",
      "Epoch 16, Loss: 0.3056658208370209\n",
      "Epoch 17, Loss: 0.28846195340156555\n",
      "Epoch 18, Loss: 0.2723430097103119\n",
      "Epoch 19, Loss: 0.2573758065700531\n",
      "Epoch 20, Loss: 0.24362467229366302\n",
      "Epoch 21, Loss: 0.23114943504333496\n",
      "Epoch 22, Loss: 0.2200024574995041\n",
      "Epoch 23, Loss: 0.2102261334657669\n",
      "Epoch 24, Loss: 0.20184926688671112\n",
      "Epoch 25, Loss: 0.19488345086574554\n",
      "Epoch 26, Loss: 0.1893189698457718\n",
      "Epoch 27, Loss: 0.18512074649333954\n",
      "Epoch 28, Loss: 0.18222419917583466\n",
      "Epoch 29, Loss: 0.18053193390369415\n",
      "Epoch 30, Loss: 0.17991143465042114\n",
      "Epoch 31, Loss: 0.18019415438175201\n",
      "Epoch 32, Loss: 0.18117767572402954\n",
      "Epoch 33, Loss: 0.18263103067874908\n",
      "Epoch 34, Loss: 0.18430458009243011\n",
      "Epoch 35, Loss: 0.1859453171491623\n",
      "Epoch 36, Loss: 0.18731766939163208\n",
      "Epoch 37, Loss: 0.18822775781154633\n",
      "Epoch 38, Loss: 0.18854661285877228\n",
      "Epoch 39, Loss: 0.1882249265909195\n",
      "Epoch 40, Loss: 0.18729400634765625\n",
      "Epoch 41, Loss: 0.1858530193567276\n",
      "Epoch 42, Loss: 0.1840457320213318\n",
      "Epoch 43, Loss: 0.18203489482402802\n",
      "Epoch 44, Loss: 0.17997832596302032\n",
      "Epoch 45, Loss: 0.17801110446453094\n",
      "Epoch 46, Loss: 0.17623473703861237\n",
      "Epoch 47, Loss: 0.17471285164356232\n",
      "Epoch 48, Loss: 0.17347277700901031\n",
      "Epoch 49, Loss: 0.17251034080982208\n",
      "Epoch 50, Loss: 0.17179755866527557\n",
      "Epoch 51, Loss: 0.17129050195217133\n",
      "Epoch 52, Loss: 0.17093761265277863\n",
      "Epoch 53, Loss: 0.1706857532262802\n",
      "Epoch 54, Loss: 0.17048591375350952\n",
      "Epoch 55, Loss: 0.17029668390750885\n",
      "Epoch 56, Loss: 0.17008686065673828\n",
      "Epoch 57, Loss: 0.16983632743358612\n",
      "Epoch 58, Loss: 0.16953639686107635\n",
      "Epoch 59, Loss: 0.1691889613866806\n",
      "Epoch 60, Loss: 0.16880501806735992\n",
      "Epoch 61, Loss: 0.16840249300003052\n",
      "Epoch 62, Loss: 0.16800373792648315\n",
      "Epoch 63, Loss: 0.1676325798034668\n",
      "Epoch 64, Loss: 0.16731131076812744\n",
      "Epoch 65, Loss: 0.16705749928951263\n",
      "Epoch 66, Loss: 0.16688157618045807\n",
      "Epoch 67, Loss: 0.1667850762605667\n",
      "Epoch 68, Loss: 0.16676008701324463\n",
      "Epoch 69, Loss: 0.16679024696350098\n",
      "Epoch 70, Loss: 0.16685347259044647\n",
      "Epoch 71, Loss: 0.16692601144313812\n",
      "Epoch 72, Loss: 0.1669866293668747\n",
      "Epoch 73, Loss: 0.1670205146074295\n",
      "Epoch 74, Loss: 0.1670212298631668\n",
      "Epoch 75, Loss: 0.16699077188968658\n",
      "Epoch 76, Loss: 0.16693775355815887\n",
      "Epoch 77, Loss: 0.1668744534254074\n",
      "Epoch 78, Loss: 0.16681323945522308\n",
      "Epoch 79, Loss: 0.16676421463489532\n",
      "Epoch 80, Loss: 0.16673342883586884\n",
      "Epoch 81, Loss: 0.1667223423719406\n",
      "Epoch 82, Loss: 0.16672848165035248\n",
      "Epoch 83, Loss: 0.16674666106700897\n",
      "Epoch 84, Loss: 0.16677045822143555\n",
      "Epoch 85, Loss: 0.16679351031780243\n",
      "Epoch 86, Loss: 0.1668107509613037\n",
      "Epoch 87, Loss: 0.16681911051273346\n",
      "Epoch 88, Loss: 0.16681762039661407\n",
      "Epoch 89, Loss: 0.16680727899074554\n",
      "Epoch 90, Loss: 0.16679047048091888\n",
      "Epoch 91, Loss: 0.166770339012146\n",
      "Epoch 92, Loss: 0.1667502373456955\n",
      "Epoch 93, Loss: 0.16673272848129272\n",
      "Epoch 94, Loss: 0.1667196899652481\n",
      "Epoch 95, Loss: 0.16671167314052582\n",
      "Epoch 96, Loss: 0.166708305478096\n",
      "Epoch 97, Loss: 0.16670827567577362\n",
      "Epoch 98, Loss: 0.16670997440814972\n",
      "Epoch 99, Loss: 0.166711688041687\n",
      "Epoch 100, Loss: 0.16671214997768402\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, torch.tensor([[1.0], [0.0], [1.0]]))  # Example target\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50169c9-be61-44cf-8006-b957f3bdd313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b721adc-0208-4287-a4b2-01c4bd8f4c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
